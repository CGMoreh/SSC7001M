---
title: "Week 3: Simple linear regression"
output:
  rmdformats::readthedown:
      code_download: true
      highlight: tango
---

# Introduction
- What are the aims of regression?
  - Regression for prediction
  - Regression for causal analysis

## Setup and packages

We will use three packages today: the `tidyverse`, `mosaic`, `ggformula`. To load a package, you use the `library()` function, wrapped around the name of a package. I've put the code to load one package into the chunk below. Add the other two you need. 

```{r include=FALSE}
knitr::opts_chunk$set(
  fig.width = 10, fig.height = 6, fig.retina = 2,
  warning = FALSE, message = FALSE, eval=T)
```

```{r, include=TRUE}
library(tidyverse)
library(mosaic)
library(ggformula)
```

## Loading in data


Let's look at a dataset of PM Boris Johnson's public approval before and after the COVID lockdowns. 
We have a set of predictor variables: (1) COVID deaths over time and (2) the monthly unemployment rate. The main variables in the dataset are the following:

| Name            | Description                                                                                                  |
|-----------------|--------------------------------------------------------------------------------------------------------------|
| `Poll_Date`     | Date of the poll (y-m-d)? |
| `Sample_Size`   | The number of respondents                                               |
| `Net_Positive`  | PM approval (based on a four-point Likert-scale)                                               |
| `Unemployment_Rate_Rounded` | Unemployment rate before the month of the poll                                                  |
| `Cumulative_Deaths_10k`       | Cumulative number of Covid deaths during the poll period                                                 |
| `Monthly_Deaths_10k`          | Covid deaths in month before poll                                                          |
| `Lockdown_Indicator`     | Indicator whether lockdown was in place during month of poll (0/1) |

We can load the dataset directly from the online course data folder:

```{r}
bj <- readRDS(url("https://cgmoreh.github.io/SSC7001M/data/BorisJohnson_Approval2.rds"))
```

We can visualise the time-trend of approval ratings using the `gf_line` graph option from the `mosaic` package:

```{r}
gf_line(Net_Positive ~ Poll_Date, data = bj)
```


# Do the number of Covid deaths affect popularity?

## Data visualization for two quantitative variables

Our main data visualization for two quantitative variables is a scatterplot. 

To make our visualization, we will use a function that begins with `gf_`. This time, the thing after the underscore is `point`, as in `gf_point()`. This function, like all functions in formula syntax, wants a formula as its first argument. 

Since we looking at a relationship between two variables, we use the $y~x$ syntax, which is the "formula." The `gf_` functions want another argument as well, which is the dataset where the variable is located. If you don't provide this, the function won't know where to look for the variables. 

Let's see an example; let's visualise the relationship between approval and monthly Covid-19 death rates:

```{r}
gf_point(Net_Positive ~ Monthly_Deaths_10k, data = bj)
```

Does this plot show a positive association, negative association, or no association? If it shows an association, how strong would you say it is?

As a first step to answering these questions, we can add an additional 'fit' line to the scatterplot:

```{r}
gf_point(Net_Positive ~ Monthly_Deaths_10k, data = bj) %>% 
  gf_lm()
```


## Summary statistics for two quantitative variables

One way to quantify the strength and direction of the relationship is with correlation. To find this, we use the `cor()` function, which takes standard formula syntax. 

```{r}
cor(Net_Positive ~ Monthly_Deaths_10k, data = bj)
```
*Note: If we get an 'NA' value, that means that we have some missing values ('NA's) in at least one observation. To get results in such a case, we need to tell `R` to use only complete observations (i.e. those cases without any missing values). `cor()` doesn't use the standard `na.rm` argument, so we instead need to tell it what to `use`. In this case, we'd like to use "complete observations" by adding `use = "complete.obs"` to our function arguments:*

```{r, eval=FALSE}
cor(Net_Positive ~ Monthly_Deaths_10k, data = bj, use = "complete.obs")
```

We see some association in both the fit-line and the correlation coefficient; but: how strong would you say it is?

## Fit a normal linear regression model

Another way to study the relationship between two quantitative variables is to fit a linear model. R has a function that does least squares regression, called `lm()` for linear model. This also takes formula syntax. You can just run the function in your Console or RMarkdown document and get a little information about your model,

```{r}
## Do the number of Covid deaths affect popularity?

lm(Net_Positive ~ Monthly_Deaths_10k, data = bj)
```

but, it's better practice to assign your model object to a name, so you can refer back to it later, and get more information about it. Recall that the assignment operator in R is `<-`. I usually call my models `m1`, `m2`, etc., but you could think of a better name to use (like `deathmodel` or similar) to remind you what it's about. 

```{r}
m1 <- lm(Net_Positive ~ Monthly_Deaths_10k, data = bj)
```

When we run this code, nothing prints out. But, a new object should appear in our RStudio Environment pane. Now, we can run R functions on that model object. The most useful one is `summary()`,

```{r}
summary(m1)
```

The same model coefficients are shown here, but there is also a lot more information about things like the $R^2$ value. 

```{r better looking table}
regtab1 <- coef(summary(m1))
rownames(regtab1) <- c("$\\beta_0$", "$\\beta_1$")
knitr::kable(regtab1)
```


## Interpreting coefficients
Let's interpret our model coefficients. Here are the generic sentences I prefer:

**Intercept** If the value of [explanatory variable] was zero, our model would predict [response variable] to be [intercept value].

**Slope** For a one-[unit] increase in [explanatory variable], our model would predict a [slope value]-[unit] [increase/decrease] in [response variable]. 

Let's apply that to this model:


$\hat{y} = -6.91 + 3.31 * MonthlyDeaths10k$

Write out the interpretation of the two coefficients (the 'intercept' and the 'slope') in your own words:


## Predicting values
Models are also useful for prediction. There are more programmatic ways to do prediction in R, but for now I recommend you just use R as a big calculator. Let's see what the model would predict for a monthly death rate of 2,000:

```{r}
-6.91 + 3.31 * 2
```

What does the model predict?

## Residuals
We are also interested in whether our model overpredicts or underpredicts certain points. We can compute a residual, which is $observed - expected$ or $y_i-\hat{y}_i$. We can calculate, for instance, the residual for the data taken on poll-date 2020-07-06:

```{r}
## Expected:
-6.91 + 3.31 * 0.1150

## Observed difference:
-6 - (-6.91 + 3.31 * 0.1150)

```
We find that for this particular data point our model has over-predicted the approval level compared to the actual data.

```{r}
fitted(m1)
plot(fitted(m1), bj$Net_Positive)
```

# EXERCISES

# 1. Does unemployment affect popularity?

```{r, eval=FALSE}
## Does unemployment affect popularity?

m2 <- ...

```

# 2. Does lockdown status affect popularity?

```{r, eval=FALSE}
## Does lockdown status affect popularity?
m3 <- ...

```

# 3. Does education affect social trust?

Using data from Österman (2021) "Can We Trust Education for Fostering Trust? Quasi-experimental Evidence on the Effect of Education and Tracking on Social Trust"

```{r import data, include=TRUE}
## Load the Osterman data:
data <- haven::read_dta("https://cgmoreh.github.io/SSC7001M/data/osterman.dta")
```

```{r, eval=FALSE, include=FALSE}
## Convert to numeric
## Columns neeing change
i <- c("ppltrst", "pplfair", "pplhlp", "dscrgrp", "eduyrs25", "inst_trustindex5", "reform1_donly_7", "reform1_eonly_7", "reform1_d_7", "paredu_a_high", "ipudrst_rev")

data[ , i] <- apply(data[ , i], 2,            # Specify own function within apply
                    function(x) as.numeric(as.character(x)))
```

## Descriptive statistics

```{r}
my.summary <- function(x, na.rm=TRUE){
  result <- c(N=length(x[!is.na(x)]),
              Mean=round(mean(x, na.rm=na.rm), 3),
              SD=round(sd(x, na.rm=na.rm), 3),
              Min=min(x, na.rm=na.rm),
              Max=max(x, na.rm=na.rm))
}


sumtab <- data.frame(sapply(data, my.summary)) %>% select(-(cntry:dweight))

knitr::kable(data.frame(t(sumtab)), caption = "Table 2 in Österman (2021)")
```


## 3.1. Build a scatter-plot of 'trustindex3' by 'eduyrs25'

## 3.2. Correlate 'trustindex3' by 'eduyrs25'

## 3.3. Regress 'trustindex3' on 'eduyrs25' and interpret the results

# 4. Does age and gender affect social trust?

## 4.1. Do the above steps for 'trustindex3' and 'agea'

## 4.2. Do the above steps for 'trustindex3' and 'female'